{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import path\n",
    "from Bio import SeqIO\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "import pymysql\n",
    "import shutil \n",
    "import urllib.request\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "sys.path.append(\"../\")\n",
    "from db_mapping import save_mapping_to_db\n",
    "con = pymysql.connect(host='127.0.0.1', unix_socket='/opt/lampp/var/mysql/mysql.sock', user='root', passwd='', db='current_project')\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_transcript(transcript_id):\n",
    "    if 'ENST' in transcript_id: \n",
    "        transcript_id_no_vs = transcript_id.split('.')[0]\n",
    "        url = 'https://rest.ensembl.org/sequence/id/'+transcript_id_no_vs+'?content-type=text/x-fasta;type=protein'\n",
    "    else:\n",
    "        url = 'https://www.ncbi.nlm.nih.gov/sviewer/viewer.cgi?tool=portal&save=file&log$=seqview&db=protein&report=fasta&id='\\\n",
    "                        +transcript_id+'&extrafeat=null&conwithfeat=on'\n",
    "\n",
    "    fp = urllib.request.urlopen(url)\n",
    "    mybytes = fp.read()\n",
    "\n",
    "    sequence = mybytes.decode(\"utf8\")\n",
    "    fp.close()\n",
    "    sequence = '\\n'.join(sequence.split('\\n')[1:])\n",
    "    sequence = '>'+transcript_id+' [Homo sapiens]\\n' + sequence\n",
    "\n",
    "    return sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_lists = {}\n",
    "fasta_lists = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ensts = pd.concat([pd.read_sql(\"SELECT DISTINCT canonical_transcript FROM gnomad\", con).iloc[:,0],\n",
    "          pd.read_sql(\"SELECT DISTINCT accession_number FROM CosmicMutantExport WHERE accession_number \"+\\\n",
    "                      \"LIKE 'ENST%'\", con).iloc[:,0]])\n",
    "df_ensts = df_ensts.unique()\n",
    "pd.Series(df_ensts).to_csv('/opt/current_project/db/mapping/WHOLE_ENST_IDS.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = '/opt/current_project' \n",
    "db_path = '/opt/current_project/db'\n",
    "sequences_path = path.join(project_path, 'results', 'sequences')\n",
    "\n",
    "if path.exists(sequences_path):\n",
    "    shutil.rmtree(sequences_path)\n",
    "\n",
    "os.makedirs(sequences_path)\n",
    "\n",
    "all_relevant_fasta_sequences = ''\n",
    "\n",
    "\n",
    "# Fetch the transcript ids that have variants\n",
    "transcripts_in_the_db = pd.concat([pd.read_sql(\"SELECT DISTINCT nm_id FROM clinvar\", con).iloc[:,0], \n",
    "          pd.read_sql(\"SELECT DISTINCT canonical_transcript FROM gnomad\", con).iloc[:,0],\n",
    "          pd.read_sql(\"SELECT DISTINCT accession_number FROM CosmicMutantExport WHERE accession_number \"+\\\n",
    "                      \"LIKE 'ENST%'\", con).iloc[:,0]],\n",
    "          axis=0)\n",
    "transcripts_in_the_db = transcripts_in_the_db.unique()\n",
    "\n",
    "nm_to_transcript_id = pd.read_csv(path.join(db_path, 'mapping', 'NM_NP_GeneID.list'), sep='\\t', header=None).iloc[:, :2]\n",
    "nm_to_transcript_id.columns = ['retrieval_id', 'transcript_id']\n",
    "enst_to_transcript_id = pd.read_csv(path.join(db_path, 'mapping', 'ENST_ENSTV_GeneID.list')).iloc[:, :2]\n",
    "enst_to_transcript_id.columns = ['retrieval_id', 'transcript_id']\n",
    "\n",
    "\n",
    "retrieval_id_to_transcript_id = pd.concat([nm_to_transcript_id, enst_to_transcript_id], axis=0, ignore_index=True)\n",
    "retrieval_id_to_transcript_id = retrieval_id_to_transcript_id.loc[\n",
    "                                retrieval_id_to_transcript_id['retrieval_id'].drop_duplicates().index, :]\n",
    "\n",
    "retrieval_id_to_transcript_id = retrieval_id_to_transcript_id.set_index('retrieval_id')\n",
    "\n",
    "retrieval_id_to_transcript_id = retrieval_id_to_transcript_id.loc[retrieval_id_to_transcript_id.index.\\\n",
    "                                                                  intersection(transcripts_in_the_db)]\n",
    "retrieval_id_to_transcript_id = retrieval_id_to_transcript_id.set_index('transcript_id')\n",
    "\n",
    "species_list = ['Homo_sapiens', 'Homo_sapiens_Ensembl']\n",
    "\n",
    "if not path.exists(sequences_path):\n",
    "    os.makedirs(sequences_path)\n",
    "    \n",
    "fasta_lists['Homo_sapiens'] = {}\n",
    "\n",
    "for species in tqdm(species_list):\n",
    "        \n",
    "    fasta_sequence_file = path.join(db_path, 'proteins', species+'.faa')\n",
    "\n",
    "    fasta_sequences = SeqIO.parse(fasta_sequence_file, \"fasta\")\n",
    "    for fasta in tqdm(fasta_sequences):\n",
    "        transcript_id, sequence = fasta.id, str(fasta.seq)\n",
    "        if species == 'Homo_sapiens_Ensembl':\n",
    "            description_map = {desc.split(':')[0]: desc.split(':')[1] for desc in fasta.description.split(' ') if \n",
    "                                  len(desc.split(':')) > 1}\n",
    "            transcript_id = description_map['transcript']\n",
    "        sequence = '>'+transcript_id+' [Homo sapiens]\\n' + sequence\n",
    "        \n",
    "        filename = path.join(sequences_path, transcript_id+'.fasta')\n",
    "\n",
    "        if transcript_id not in retrieval_id_to_transcript_id.index:\n",
    "            continue\n",
    "\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(sequence)\n",
    "\n",
    "        fasta_lists['Homo_sapiens'][transcript_id] = sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for transcript_id in tqdm(retrieval_id_to_transcript_id.index.difference(fasta_lists['Homo_sapiens'])):\n",
    "    try:\n",
    "        fasta_lists['Homo_sapiens'][transcript_id] = fetch_transcript(transcript_id)    \n",
    "        print(fasta_lists['Homo_sapiens'][transcript_id])\n",
    "    except Exception as e:\n",
    "        print(e, transcript_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "human_transcripts = glob(path.join(sequences_path, '*'))\n",
    "homology_list = pd.read_csv(path.join(db_path,'orthology','Homology.list'), sep='\\t', dtype=str)\n",
    "\n",
    "species_list = ['Pan_troglodytes', 'Macaca_mulatta', 'Rattus_norvegicus', 'Mus_musculus', 'Danio_rerio', \n",
    "            'Xenopus_tropicalis', 'Drosophila_melanogaster', 'Caenorhabditis_elegans']\n",
    "homology_list.columns = ['Homo_sapiens'] + species_list\n",
    "homology_list = homology_list.set_index('Homo_sapiens')\n",
    "\n",
    "enst_to_gene_id = pd.read_csv(path.join(db_path, 'mapping', 'NewCurated_ENSTvsGENEID.csv'))\n",
    "enst_to_gene_id.columns = ['transcript_id', 'gene_id']\n",
    "np_to_gene_id = pd.read_csv(path.join(db_path, 'mapping', 'NM_NP_GeneID.list'), sep='\\t').iloc[:, 1:] \n",
    "np_to_gene_id.columns = ['transcript_id', 'gene_id']\n",
    "\n",
    "transcript_id_to_gene_id = pd.concat([enst_to_gene_id, np_to_gene_id], axis=0, ignore_index=True)\n",
    "\n",
    "gene_id_to_transcript_ids = pd.concat([enst_to_gene_id, np_to_gene_id], axis=0, ignore_index=True)\n",
    "\n",
    "for species in species_list:\n",
    "    species_list_file = path.join(db_path, 'mapping', 'NP_tables', species+'.list')\n",
    "    print(species_list_file)\n",
    "    transcript_lists[species] = pd.read_csv(species_list_file, sep='\\t')\n",
    "    transcript_list = transcript_lists[species][['Protein product', 'GeneID']]\n",
    "    transcript_list.columns = ['transcript_id', 'gene_id']\n",
    "    \n",
    "    transcript_id_to_gene_id = pd.concat([transcript_id_to_gene_id, transcript_list],\n",
    "                                        axis=0, ignore_index=True)\n",
    "    gene_id_to_transcript_ids = pd.concat([gene_id_to_transcript_ids, transcript_list],\n",
    "                                        axis=0, ignore_index=True)\n",
    "    \n",
    "    fasta_lists[species] = {} \n",
    "    fasta_sequence_file = path.join(db_path, 'proteins', species+'.faa')\n",
    "    \n",
    "    fasta_sequences = SeqIO.parse(fasta_sequence_file, \"fasta\")\n",
    "    for fasta in tqdm(fasta_sequences):\n",
    "        transcript_id, sequence = fasta.id, str(fasta.seq)\n",
    "        transcript_id = transcript_id.split('.')[0]\n",
    "        fasta_lists[species][transcript_id] = sequence\n",
    "    \n",
    "    \n",
    "\n",
    "transcript_id_to_gene_id = transcript_id_to_gene_id.dropna()\n",
    "transcript_id_to_gene_id.loc[:, 'transcript_id'] = transcript_id_to_gene_id['transcript_id'].apply(lambda x: x.split('.')[0])\n",
    "transcript_id_to_gene_id.loc[:, 'gene_id'] = transcript_id_to_gene_id.loc[:, 'gene_id'].astype(str) \n",
    "transcript_id_to_gene_id = transcript_id_to_gene_id.set_index('transcript_id')\n",
    "\n",
    "gene_id_to_transcript_ids = gene_id_to_transcript_ids.dropna()\n",
    "gene_id_to_transcript_ids.loc[:, 'gene_id'] = gene_id_to_transcript_ids.loc[:, 'gene_id'].astype(str)\n",
    "\n",
    "gene_id_to_transcript_ids.loc[:, 'transcript_id'] = gene_id_to_transcript_ids['transcript_id'].apply(lambda x: x.split('.')[0])\n",
    "gene_id_to_transcript_ids = gene_id_to_transcript_ids.groupby('gene_id')['transcript_id'].apply(lambda x: ','.join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seqs_with_homology_path = '/opt/current_project/results/seqs_with_homology/'\n",
    "\n",
    "if path.exists(seqs_with_homology_path):\n",
    "    shutil.rmtree(seqs_with_homology_path)\n",
    "\n",
    "os.makedirs(seqs_with_homology_path)\n",
    "\n",
    "for transcript_file in tqdm(human_transcripts):\n",
    "    with open(transcript_file, 'r') as f:\n",
    "        current_fasta = f.read()\n",
    "    human_transcript_id_orig = current_fasta.split('\\n')[0].split(' ')[0].replace('>', '') \n",
    "    human_transcript_id = human_transcript_id_orig.split('.')[0]\n",
    "    if human_transcript_id not in transcript_id_to_gene_id.index:\n",
    "        continue\n",
    "        \n",
    "    if pd.isna(transcript_id_to_gene_id.loc[human_transcript_id, 'gene_id']):\n",
    "        continue\n",
    "    if ' ' in str(transcript_id_to_gene_id.loc[human_transcript_id, 'gene_id']):\n",
    "        print(transcript_id, \n",
    "              transcript_id_to_gene_id.loc[human_transcript_id, 'gene_id'])\n",
    "        continue\n",
    "    \n",
    "    human_gene_id = transcript_id_to_gene_id.loc[human_transcript_id, 'gene_id']\n",
    "    \n",
    "    if human_gene_id not in homology_list.index:\n",
    "        continue\n",
    "    \n",
    "    transcript_ids = set()\n",
    "    \n",
    "    for species, homolog_gene_ids in homology_list.loc[human_gene_id].to_dict().items():\n",
    "        if pd.isna(homolog_gene_ids):\n",
    "            continue\n",
    "        homolog_gene_ids = homolog_gene_ids.split(',')\n",
    "        for gene_id in homolog_gene_ids:\n",
    "            if gene_id == '':\n",
    "                continue\n",
    "            if gene_id not in gene_id_to_transcript_ids.index:\n",
    "                continue\n",
    "            \n",
    "            homolog_transcript_ids = gene_id_to_transcript_ids.loc[gene_id].split(',')\n",
    "            \n",
    "            for transcript_id in homolog_transcript_ids:\n",
    "                if transcript_id not in fasta_lists[species]:\n",
    "                    continue\n",
    "                if transcript_id in transcript_ids:\n",
    "                    continue\n",
    "                \n",
    "                if len(homolog_transcript_ids) > 3 and random.randint(1,2) == 1:\n",
    "                    continue\n",
    "\n",
    "                transcript_ids.add(transcript_id)\n",
    "                \n",
    "                current_fasta += '\\n'\n",
    "                current_fasta += '>'+transcript_id+' ['+species.replace('_',' ')+']'\n",
    "                current_fasta += '\\n'+fasta_lists[species][transcript_id]\n",
    "    \n",
    "    with open(path.join(seqs_with_homology_path, human_transcript_id_orig +'.fasta'), 'w') as f:\n",
    "        f.write(current_fasta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "blast_db_path = path.join(db_path, 'blast_db/')\n",
    "\n",
    "if path.exists(blast_db_path):\n",
    "    shutil.rmtree(blast_db_path)\n",
    "\n",
    "os.makedirs(blast_db_path)\n",
    "\n",
    "all_fasta = '\\n'.join(list(fasta_lists['Homo_sapiens'].values()))\n",
    "\n",
    "curated_file_path = path.join(blast_db_path, 'convart_curated_fasta.fasta')\n",
    "\n",
    "with open(curated_file_path, 'w') as f:\n",
    "    f.write(all_fasta)\n",
    "\n",
    "\n",
    "os.system(\"makeblastdb -in \"+curated_file_path+\" -out \"+\\\n",
    "    path.join(blast_db_path, 'convartProteome')+\\\n",
    "    \" -title \"+path.join(blast_db_path, 'convartProteome')+\" -dbtype prot\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "makeblastdb -in /opt/current_project/db/blast_db/convart_curated_fasta.fasta -out /opt/current_project/db/blast_db/convartProteome -title /opt/current_project/db/blast_db/convartProteome -dbtype prot\n"
     ]
    }
   ],
   "source": [
    "print(\"makeblastdb -in \"+curated_file_path+\" -out \"+\\\n",
    "    path.join(blast_db_path, 'convartProteome')+\\\n",
    "    \" -title \"+path.join(blast_db_path, 'convartProteome')+\" -dbtype prot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python create_alignments.py construct_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matching = pd.read_sql(\"\"\"SELECT GROUP_CONCAT(if(id like 'NP%', id, null)) AS np_id,\n",
    "    GROUP_CONCAT(if(id like 'ENST%', id, null)) AS enst_id \n",
    "    FROM `convart_gene` WHERE species_id = 'Homo sapiens' GROUP BY sequence HAVING COUNT(id) > 1 AND np_id is NOT NULL \n",
    "    ORDER BY id ASC\n",
    "    \"\"\", con)\n",
    "df_matching.loc[:, 'enst_id'] = res.loc[:, 'enst_id'].replace({None: \"\"})\n",
    "\n",
    "df_matching = explode_str(df_matching, 'enst_id', ',')\n",
    "df_matching = explode_str(df_matching, 'np_id', ',')\n",
    "\n",
    "df_matching = df_matching.set_index('np_id')\n",
    "df_matching.columns = ['ENST']\n",
    "\n",
    "save_mapping_to_db(df_matching, con, cur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_np_ncbi = pd.read_sql(\"\"\"SELECT nc_hum.meta_value AS np_id, nc_hum.ncbi_gene_id FROM ncbi_gene_meta AS nc_hum\n",
    "        WHERE meta_key='protein_number' AND meta_value LIKE 'NP%' GROUP BY nc_hum.meta_value\"\"\", con)\n",
    "df_np_ncbi = df_np_ncbi.set_index('np_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matching_with_ncbi = df_matching.copy()\n",
    "df_matching_with_ncbi.loc[:, 'ncbi_id'] = df_matching_with_ncbi.index.map(lambda x: df_np_ncbi.loc[x, 'ncbi_gene_id'])\n",
    "for _, row in df_matching_with_ncbi.iterrows():\n",
    "    cur.execute(\"INSERT IGNORE INTO ncbi_gene_meta (ncbi_gene_id, meta_key, meta_value) VALUES (%s, 'protein_number', %s)\", \n",
    "                        (row['ncbi_id'], row['ENST']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
